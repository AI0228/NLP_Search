{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/kiran/Python_3/quora-question-pairs_2021/train.csv/train_for_similarity.txt', delimiter = \"\\t\",header=None)\n",
    "df = df[0:25000]\n",
    "#df1 = df.iloc[0::2]\n",
    "#df2 = df.iloc[1::2]\n",
    "#df1.reset_index(drop=True,inplace=True)\n",
    "#df2.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = model.encode(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which language is the best for web development?\n",
      "What are the best web products to develop?\n",
      "What are the best productivity tools for web development?\n",
      "What are the best programming languages to learn for web development?\n",
      "What is the best Perl web app framework?\n",
      "What are the best websites to prepare for placements?\n",
      "What is the best way to get back into web application penetration testing?\n",
      "What's the best way to find a job as a web developer?\n",
      "What is your favourite web programming language?\n",
      "What are good ways to learn how to improve web development?\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings1 = model.encode(\"What is the best course for web development?\")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sim_arr=cosine_similarity(\n",
    "    [sentence_embeddings1],\n",
    "    sentence_embeddings[:]\n",
    ")\n",
    "di=dict(zip(sim_arr[0],df[0]))\n",
    "\n",
    "sim_arr=np.sort(sim_arr[0])[::-1]\n",
    "sim_arr=sim_arr[0:10]\n",
    "\n",
    "for i in sim_arr:\n",
    "    print(di[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing it without SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218a819e76e04525997011eec4aa05cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=438007537.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionary to store tokenized sentences\n",
    "tokens = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "for sentence in sentences:\n",
    "    # encode each sentence and append to dictionary\n",
    "    new_tokens = tokenizer.encode_plus(sentence, max_length=128,\n",
    "                                       truncation=True, padding='max_length',\n",
    "                                       return_tensors='pt')\n",
    "    tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "\n",
    "# reformat list of tensors into single tensor\n",
    "tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "tokens['attention_mask'] = torch.stack(tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**tokens)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0052, -0.6296,  1.2486,  ..., -0.0733, -0.2491, -0.0506],\n",
       "         [ 0.1923, -0.9253,  1.3169,  ...,  0.1456,  0.0132, -0.2964],\n",
       "         [ 0.1014, -0.9976,  1.2731,  ...,  0.1544, -0.1575, -0.0798],\n",
       "         ...,\n",
       "         [ 0.3130, -0.7524,  1.1886,  ..., -0.1194, -0.2089,  0.0165],\n",
       "         [ 0.2546, -0.7417,  1.1883,  ..., -0.1229, -0.2080,  0.0803],\n",
       "         [ 0.2244, -0.7082,  1.2314,  ..., -0.0896, -0.2728,  0.0759]],\n",
       "\n",
       "        [[-0.4668, -0.0189,  0.4151,  ...,  0.2630, -0.4392, -0.1010],\n",
       "         [-0.6711, -0.2192,  0.2173,  ...,  0.0236, -0.2320, -0.1433],\n",
       "         [-0.5410,  0.3427, -0.0292,  ...,  0.1073, -0.5477,  0.0679],\n",
       "         ...,\n",
       "         [-0.3078,  0.0607,  0.2494,  ...,  0.2835, -0.7488, -0.0522],\n",
       "         [-0.3585,  0.0552,  0.1931,  ...,  0.2523, -0.7587, -0.0163],\n",
       "         [-0.4766, -0.0714,  0.2329,  ...,  0.2959, -0.6838, -0.1150]],\n",
       "\n",
       "        [[ 0.0349, -0.6494,  1.6127,  ..., -0.0366, -0.0330, -0.1680],\n",
       "         [ 0.1675, -0.9080,  1.5879,  ...,  0.1771,  0.2052, -0.3501],\n",
       "         [ 0.1267, -0.8917,  1.5309,  ...,  0.0837,  0.0159, -0.1921],\n",
       "         ...,\n",
       "         [ 0.2450, -0.8097,  1.4101,  ..., -0.0195, -0.0385, -0.1351],\n",
       "         [ 0.2031, -0.7692,  1.4232,  ..., -0.0060, -0.0491, -0.0601],\n",
       "         [ 0.1779, -0.7369,  1.4761,  ...,  0.0242, -0.0861, -0.0603]],\n",
       "\n",
       "        [[ 0.1142, -0.7040,  1.3672,  ...,  0.3260,  0.0017,  0.0278],\n",
       "         [ 0.2700, -0.9794,  1.3465,  ...,  0.5507,  0.1943, -0.1734],\n",
       "         [ 0.1926, -0.9990,  1.2684,  ...,  0.5118,  0.0169,  0.0555],\n",
       "         ...,\n",
       "         [ 0.3406, -0.8436,  1.2420,  ...,  0.2657, -0.0512,  0.0670],\n",
       "         [ 0.3057, -0.8161,  1.2500,  ...,  0.2604, -0.0467,  0.1350],\n",
       "         [ 0.2549, -0.7904,  1.3047,  ...,  0.2967, -0.1003,  0.1411]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = outputs.last_hidden_state\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 768])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = tokens['attention_mask']\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 768])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 768])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings = embeddings * mask\n",
    "masked_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0052, -0.6296,  1.2486,  ..., -0.0733, -0.2491, -0.0506],\n",
       "         [ 0.1923, -0.9253,  1.3169,  ...,  0.1456,  0.0132, -0.2964],\n",
       "         [ 0.1014, -0.9976,  1.2731,  ...,  0.1544, -0.1575, -0.0798],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.4668, -0.0189,  0.4151,  ...,  0.2630, -0.4392, -0.1010],\n",
       "         [-0.6711, -0.2192,  0.2173,  ...,  0.0236, -0.2320, -0.1433],\n",
       "         [-0.5410,  0.3427, -0.0292,  ...,  0.1073, -0.5477,  0.0679],\n",
       "         ...,\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n",
       "\n",
       "        [[ 0.0349, -0.6494,  1.6127,  ..., -0.0366, -0.0330, -0.1680],\n",
       "         [ 0.1675, -0.9080,  1.5879,  ...,  0.1771,  0.2052, -0.3501],\n",
       "         [ 0.1267, -0.8917,  1.5309,  ...,  0.0837,  0.0159, -0.1921],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n",
       "\n",
       "        [[ 0.1142, -0.7040,  1.3672,  ...,  0.3260,  0.0017,  0.0278],\n",
       "         [ 0.2700, -0.9794,  1.3465,  ...,  0.5507,  0.1943, -0.1734],\n",
       "         [ 0.1926, -0.9990,  1.2684,  ...,  0.5118,  0.0169,  0.0555],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "summed = torch.sum(masked_embeddings, 1)\n",
    "summed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "summed_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pooled = summed / summed_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0398, -0.8550,  1.2641,  ...,  0.0609, -0.2783, -0.2472],\n",
       "        [-0.7844,  0.0238,  0.2405,  ...,  0.2124, -0.5366, -0.1705],\n",
       "        [-0.0281, -0.8078,  1.5523,  ...,  0.0903, -0.0217, -0.3451],\n",
       "        [ 0.0547, -0.8911,  1.3226,  ...,  0.4829, -0.0389, -0.1081]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44401556, 0.95029956, 0.9565913 ]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from PyTorch tensor to numpy array\n",
    "mean_pooled = mean_pooled.detach().numpy()\n",
    "\n",
    "# calculate\n",
    "cosine_similarity(\n",
    "    [mean_pooled[0]],\n",
    "    mean_pooled[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "my_data = genfromtxt('embed.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
